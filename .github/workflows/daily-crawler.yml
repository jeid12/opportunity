name: Daily Crawler

on:
  schedule:
    - cron: '30 0 * * *'  # Every day at 00:30 UTC
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 gspread \
                    google-auth[urllib3] google-auth-oauthlib \
                    google-auth-httplib2 google-api-python-client

    - name: Write Google credentials to file
      run: |
        echo "$GOOGLE_CREDENTIALS" > google_credentials.json
      env:
        GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}

    - name: Run crawler
      run: python main.py

    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: crawl-results
        path: output/
